{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90ab2b0-47d2-4507-a038-f41807fed7a9",
   "metadata": {},
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac49a6a-71be-4761-876c-92f244cf4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_titles(channel_url, max_videos=5):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(channel_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page with status code {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    video_titles = []\n",
    "    for a in soup.find_all('a', id='video-title', limit=max_videos):\n",
    "        video_titles.append(a['title'])\n",
    "\n",
    "    return video_titles\n",
    "\n",
    "\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "video_titles = get_video_titles(channel_url)\n",
    "\n",
    "if video_titles:\n",
    "    for idx, title in enumerate(video_titles, start=1):\n",
    "        print(f\"Video {idx}: {title}\")\n",
    "else:\n",
    "    print(\"No videos found or an error occurred.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d63e47-b33a-44e3-b768-d0d683d10ea1",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0b665-d90c-44ab-8ccf-5c0ff3a36c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_thumbnail_urls(channel_url, max_videos=5):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(channel_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    thumbnails = []\n",
    "    for img in soup.find_all('img', {'id': 'img'})[:max_videos]:\n",
    "        if 'src' in img.attrs:\n",
    "            thumbnails.append(img['src'])\n",
    "        elif 'data-src' in img.attrs:\n",
    "            thumbnails.append(img['data-src'])\n",
    "    \n",
    "    return thumbnails\n",
    "\n",
    "\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "thumbnail_urls = get_thumbnail_urls(channel_url)\n",
    "\n",
    "if thumbnail_urls:\n",
    "    for idx, url in enumerate(thumbnail_urls, start=1):\n",
    "        print(f\"Thumbnail {idx}: {url}\")\n",
    "else:\n",
    "    print(\"No thumbnails found or an error occurred.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babe13e-a1cf-4d07-90ce-ca2046ae228b",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dabe9b-348c-4c9a-a70e-a7cdb9d1b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_titles(channel_url, max_videos=5):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(channel_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    titles = []\n",
    "    for video in soup.find_all('a', {'id': 'video-title'})[:max_videos]:\n",
    "        title = video.get('title')\n",
    "        if title:\n",
    "            titles.append(title)\n",
    "    \n",
    "    return titles\n",
    "\n",
    "\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "video_titles = get_video_titles(channel_url)\n",
    "\n",
    "if video_titles:\n",
    "    for idx, title in enumerate(video_titles, start=1):\n",
    "        print(f\"Video {idx}: {title}\")\n",
    "else:\n",
    "    print(\"No video titles found or an error occurred.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4da58a-fb9e-49d6-a736-f3563c31538f",
   "metadata": {},
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12535c5-3382-45f7-9992-068877b1d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_details(channel_url, max_videos=5):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(channel_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    video_details = []\n",
    "    videos = soup.find_all('div', {'id': 'dismissible'})[:max_videos]\n",
    "    \n",
    "    for video in videos:\n",
    "        title_tag = video.find('a', {'id': 'video-title'})\n",
    "        view_count_tag = video.find('span', {'class': 'style-scope ytd-video-meta-block'})\n",
    "        \n",
    "        if title_tag and view_count_tag:\n",
    "            title = title_tag.get('title')\n",
    "            view_count = view_count_tag.text.strip()\n",
    "            video_details.append((title, view_count))\n",
    "    \n",
    "    return video_details\n",
    "\n",
    "\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "video_details = get_video_details(channel_url)\n",
    "\n",
    "if video_details:\n",
    "    for idx, (title, views) in enumerate(video_details, start=1):\n",
    "        print(f\"Video {idx}: {title} - Views: {views}\")\n",
    "else:\n",
    "    print(\"No video details found or an error occurred.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f939e-174b-4cec-860b-ea4601213508",
   "metadata": {},
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310f1a1-fb3f-443b-800e-2110cde6743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_details(channel_url, max_videos=5):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(channel_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "   
    "    video_details = []\n",
    "    videos = soup.find_all('ytd-grid-video-renderer', {'class': 'style-scope ytd-grid-renderer'})[:max_videos]\n",
    "    \n",
    "    for video in videos:\n",
    "        title_tag = video.find('a', {'id': 'video-title'})\n",
    "        view_count_tag = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'})\n",
    "        upload_time_tag = video.find('div', {'id': 'metadata-line'}).find_all('span')[1]\n",
    "        \n",
    "        if title_tag and view_count_tag and upload_time_tag:\n",
    "            title = title_tag.get('title')\n",
    "            view_count = view_count_tag.text.strip()\n",
    "            upload_time = upload_time_tag.text.strip()\n",
    "            video_details.append((title, view_count, upload_time))\n",
    "    \n",
    "    return video_details\n",
    "\n",
    
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "video_details = get_video_details(channel_url)\n",
    "\n",
    "if video_details:\n",
    "    for idx, (title, views, upload_time) in enumerate(video_details, start=1):\n",
    "        print(f\"Video {idx}: {title} - Views: {views} - Uploaded: {upload_time}\")\n",
    "else:\n",
    "    print(\"No video details found or an error occurred.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
